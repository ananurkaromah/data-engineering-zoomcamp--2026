# Data Engineering Zoomcamp 2026 üöÄ

This repository documents my hands-on journey through the **Data Engineering Zoomcamp 2026** by DataTalksClub.

It showcases real-world data engineering skills, including building scalable data pipelines, designing data warehouses, orchestrating workflows, and processing batch & streaming data using modern tools and cloud infrastructure.

---

## üëã About Me

I am an aspiring **Data Engineer** with a strong interest in:
- Building reliable and scalable data pipelines
- Designing analytics-ready data warehouses
- Applying best practices in analytics engineering
- Working with both batch and streaming data systems

This repository serves as a **portfolio of practical data engineering work**, not just course notes.

---

## üß† What I Learned (Key Skills)

Through this program, I gained hands-on experience in:

- **Containerization & Infrastructure as Code**
  - Docker, Docker Compose
  - Terraform for cloud infrastructure provisioning (GCP)

- **Data Ingestion & Orchestration**
  - API-based ingestion
  - Incremental loading & normalization
  - Workflow orchestration using Kestra

- **Data Warehousing**
  - BigQuery fundamentals
  - Partitioning, clustering, and performance optimization
  - SQL-based analytics at scale
  - Machine Learning features in BigQuery

- **Analytics Engineering**
  - Data modeling (fact & dimension tables)
  - dbt with DuckDB & BigQuery
  - Testing, documentation, and deployment of analytics models

- **Batch Processing**
  - Apache Spark
  - DataFrames and Spark SQL
  - Understanding joins and aggregations at scale

- **Streaming Systems**
  - Apache Kafka
  - Kafka Streams & KSQL
  - Schema management with Avro

---

## üìö Program Structure

### Module 1: Containerization & Infrastructure as Code
- Docker & Docker Compose
- PostgreSQL in containers
- Terraform on Google Cloud Platform
- Homework: End-to-end local data setup

---

### Module 2: Workflow Orchestration
- Data Lakes concepts
- Workflow orchestration using **Kestra**
- Homework: Scheduled and parameterized pipelines

---

### Workshop 1: Data Ingestion
- API ingestion and pipeline scalability
- Data normalization
- Incremental loading strategies
- Homework: Production-style ingestion pipeline

---

### Module 3: Data Warehousing
- BigQuery fundamentals
- Partitioning & clustering
- Cost and performance optimization
- Machine learning in BigQuery

---

### Module 4: Analytics Engineering
- Analytics engineering principles
- dbt with DuckDB & BigQuery
- Testing, documentation, and deployment

---

### Module 5: Batch Processing
- Apache Spark fundamentals
- DataFrames & Spark SQL
- Internals of joins and aggregations

---

### Module 6: Streaming
- Apache Kafka fundamentals
- Kafka Streams and KSQL
- Schema management with Avro

---

### Final Project
- End-to-end data engineering solution
- Real-world dataset
- Cloud infrastructure, ingestion, transformation, and analytics
- Peer review and feedback process

---

## üõ†Ô∏è Tech Stack

- **Cloud**: Google Cloud Platform (GCP)
- **Containers**: Docker, Docker Compose
- **Databases**: PostgreSQL, BigQuery
- **Orchestration**: Kestra
- **Transformation**: dbt
- **Batch Processing**: Apache Spark
- **Streaming**: Apache Kafka
- **Languages**: SQL, Python

---

## üéØ Why This Repository Matters

This repository demonstrates my ability to:
- Translate business problems into data pipelines
- Work with modern data engineering tools
- Build reproducible and scalable systems
- Apply industry best practices, not just theory

It is designed to be reviewed by **recruiters, hiring managers, and fellow data engineers**.

---

## üìå Notes

- Large datasets are not committed to this repository
- Each module includes hands-on exercises and homework
- The repository is updated continuously as the program progresses

---

## üôè Acknowledgements

- DataTalksClub
- Data Engineering Zoomcamp instructors and community


